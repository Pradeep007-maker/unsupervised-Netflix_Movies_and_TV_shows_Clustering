{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - unsupervised Netflix_Movies_and_TV_shows_Clustering\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** D G V S PRADEEP\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Media outlets is exceptionally serious, and achievement is reliant upon different elements, including class, rating, creation spending plan, cast, and then some. In this unique situation, a review was led to comprehend the variables impacting the fame of films and Programs on Netflix. The review utilized a dataset containing around 12 factors to bunch the films and Network programs in view of their ubiquity and crowd inclinations. The most important phase in the examination included information fighting, where missing qualities were taken care of, and exceptional qualities were checked. The review distinguished that there were 2389 missing qualities for the 'chief' section, 718 for the 'cast' segment, 507 for the 'country' segment, and 10 for the 'date_added' segment. These missing qualities were eliminated by dropping the relating columns.\n",
        "\n",
        "Then, the review performed exploratory information investigation (EDA). The quantity of films on Netflix is more noteworthy than the quantity of Programs, with 5372 motion pictures and 2398 Television programs presently accessible on the stage. The most well-known rating for Programs is television Mama, demonstrating that a critical part of the Television programs accessible on Netflix are planned for grown-up crowds. Furthermore, television Mama is the most widely recognized rating for the two motion pictures and Programs, proposing that Netflix's substance takes special care of a basically grown-up segment, with an emphasis on mature and possibly disputable subjects. The years 2017 and 2018 had the largest number of film discharges, while 2020 had the biggest number of Program discharges. The development pace of film discharges on Netflix is essentially quicker than that of Network programs. Beginning around 2015, there has been a significant expansion in the quantity of films and Program episodes accessible on Netflix. Notwithstanding, there has been a remarkable drop in the quantity of films and Television program episodes created after 2020. Apparently Netflix has focused on expanding its film content instead of Television programs.\n",
        "\n",
        "As indicated by the countplot, apparently Netflix adds the largest number of motion pictures and Programs during the period among October and January. This period is by all accounts the most active season for Netflix regarding adding new happy to its foundation. Netflix has the biggest number of content in the US, trailed by India. India has the biggest number of films on Netflix.\n",
        "\n",
        "To bunch the shows, the review zeroed in on six key credits: chief, cast, country, type, rating, and portrayal. These traits were changed into a 10,000-include TFIDF vectorization, and Head Part Examination (PCA) was utilized to diminish the parts to 3000, catching over 80% of the difference. Then, two bunching calculations, K-Means and Agglomerative bunching, were utilized to bunch the shows. K-Means verified that the ideal number of groups was 5, while Agglomerative bunching recommended 7 bunches, which were imagined utilizing a dendrogram.\n",
        "\n",
        "At long last, a substance based recommender framework was made utilizing the comparability lattice got through cosine closeness. This framework gives customized proposals in light of the sort of show the client has watched, giving them 10 first rate ideas to investigate. In outline, the review distinguished key patterns in the Netflix dataset, including the development pace of motion pictures versus Television programs, the most active time frame for adding new satisfied, and the substance socioeconomics. Through bunching and a substance based recommender framework, the review had the option to give customized proposals in light of the client's survey history. This study gives important experiences into the variables impacting the fame of motion pictures and Network programs on Netflix, offering an establishment for additional exploration and investigation."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "\n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming serviceâ€™s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "We will be clustering similar content by matching text-based features."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# Importing Numpy & Pandas for data processing & data wrangling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Importing  tools for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "# Importing libraries for hypothesis testing\n",
        "from scipy.stats import uniform\n",
        "from scipy.stats import norm\n",
        "from scipy.stats import chi2\n",
        "from scipy.stats import t\n",
        "from scipy.stats import f\n",
        "from scipy.stats import ttest_ind\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Word Cloud library\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# library used for textual data prerocessing\n",
        "import string\n",
        "string.punctuation\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from scipy.stats import ttest_ind\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# library used for Clusters impelementation\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "# library used for building recommandation system\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vUQ5y9r3b8wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/ALMA PROJECT DATA/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(len(df[df.duplicated()]))"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "# Checking the sum of null values for each column\n",
        "\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.We have a dataset that contains Movies/TV shows in Netflix until 2019.\n",
        "\n",
        "2.The dataset has 7787 entries and 12 columns. Out of the 12 columns, 11 are of 'object' datatype and 1 is of 'numeric' datatype.\n",
        "\n",
        "3.There are no duplicate values in the dataset.\n",
        "\n",
        "4.There are five columns containing missing values. There are total 3631 missing values present in the dataset."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.show_id: Unique ID for every Movie/TV show\n",
        "\n",
        "2.type: A movie or a TV show\n",
        "\n",
        "3.title: Title of the Movie/TV show\n",
        "\n",
        "4.director: Director of the Movie/TV show\n",
        "\n",
        "5.cast: Actors in the movie\n",
        "\n",
        "6.country: Country of produciton\n",
        "\n",
        "7.date_added: Date it was added on Netflix\n",
        "\n",
        "8.release_year: Actual release year of the Movie/TV show\n",
        "\n",
        "9.rating: Movie/TV show rating\n",
        "\n",
        "10.duration: duration in minutes/number of seasons\n",
        "\n",
        "11.listed_in: Genre\n",
        "\n",
        "12.Description: The description summary"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Handling Null Values\n",
        "\n",
        "df['cast'].fillna(value='No cast',inplace=True)\n",
        "df['country'].fillna(value=df['country'].mode()[0],inplace=True)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We drop the null rows in column 'date_added' \n",
        "# 'rating' column contains insignificant portion of the data so we will drop null values from the dataset\n",
        "\n",
        "df.dropna(subset=['date_added','rating'],inplace=True)"
      ],
      "metadata": {
        "id": "E-QRB7uhfZvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We drop the 'director' column, as there are 30% null values.\n",
        "df.drop(['director'],inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "KBED4baQfZ33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "Zlgi-w3_faGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.To make our dataset analysis ready, we fill the null values in 'cast' column \n",
        "with 'No cast'.\n",
        "\n",
        "2.We filled the null values in 'country' column with the mode of the column.\n",
        "\n",
        "3.Then we drop rows with null values in 'date_added' and 'rating' columns.\n",
        "\n",
        "4.Also we drop 'director' column as there are 30% null values.\n",
        "\n",
        "5.We then recheckced if there are any remaining null values in the dataset."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "plt.pie(df['type'].value_counts(),labels = df['type'].value_counts().keys().tolist(),autopct='%.0f%%')\n",
        "plt.title('type')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie charts are one of the best ways for univariate analysis of categorical data."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of 7787 rows in our dataset, we have 69% of them as movies, the rest 31% is TV shows."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight that there are more movies on Netflix than TV shows is unlikely to have a significant positive or negative business impact on its own. However, this information could be used in conjunction with other insights and data to inform business decisions.\n",
        "\n",
        "For example, if Netflix notices that TV shows are more popular with its subscribers than movies, it may decide to focus more on acquiring TV show content. Alternatively, if it sees that its original movie productions are gaining popularity, it may decide to invest more in that area."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "df['country'].value_counts().head(10).plot(kind='bar')\n",
        "\n",
        "plt.title('Country of produciton')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the values in both x & y axes are not in series / continuous, the bar chart is the best option as details are displayed explicitly."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The US and India are top Movie/TV show producing countries, followed by UK and Japan."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix chooses to produce movies/tv shows in countries that has good viewership potential and great content. The US and India tops these checklists. In addition to this, Netflix can use this data to recommend content based on thier geographic location."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "# Plotting a countplot for categorical variable- 'release_year' (Top 10 years)\n",
        "\n",
        "df['release_year'].value_counts().head(10).plot(kind='bar')\n",
        "\n",
        "plt.title('Release year')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the values in both x & y axes are not in series / continuous, the bar chart is the best option as details are displayed explicitly."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As they call these times as golden age of cinema & tv shows, we can see that highest titles released were in the '10s. 2018 topped our list compared to 2019 & 2020."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights may have a positive business impact for Netflix, as they show that increasing their movie content could be a successful strategy. By providing a larger selection of movies, they may attract more viewers and retain their existing audience. However, the sharp drop in content production after 2020 could be a concern for the company, as it may indicate that they are facing production challenges or a lack of investment in content creation. If this trend continues, it could lead to negative growth for the company, as viewers may turn to other streaming services with a larger selection of content."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "tv_shows = df[df['type']=='TV Show']\n",
        "movies = df[df['type']=='Movie']"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group TV shows by 'rating' and count the number of shows in each rating category\n",
        "tv_ratings = tv_shows.groupby(['rating'])['show_id'].count().reset_index(name='count').sort_values(by='count',ascending=False)\n",
        "\n",
        "# set figure dimensions\n",
        "fig_dims = (14,7)\n",
        "\n",
        "# create a figure and axis object with specified dimensions\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "\n",
        "# create a point plot using Seaborn's pointplot() function, with 'rating' on the x-axis and 'count' on the y-axis\n",
        "sns.pointplot(x='rating',y='count',data=tv_ratings)\n",
        "\n",
        "# set the plot title and font size\n",
        "plt.title('TV Show Ratings',size='20')\n",
        "\n",
        "# display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KEoe_w3imzuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The seaorn pointplot effectively shows the distribution of TV show & moviesratings in a clear and concise manner. Overall, this chart provides a quick and informative overview of the ratings landscape for TV shows & movies on Netflix."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the dataset, TV-MA is the most common rating for TV shows, with the highest number of occurrences in the 'rating' column. This indicates that a significant portion of the TV shows available on Netflix are intended for adult audiences.According to the dataset, TV-MA is the most common rating for both movies and TV shows. This indicates that a significant portion of the content available on Netflix is intended for adult audiences. Specifically, TV-MA has the highest number of occurrences in the 'rating' column for TV shows, while for movies it is also the most common rating. This suggests that Netflix's content caters to a primarily adult demographic, with a focus on mature and potentially controversial themes."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can have a positive impact on Netflix's business strategy. Knowing that TV-MA is the most common rating for both movies and TV shows, Netflix can continue to focus on producing and acquiring content that appeals to adult audiences. This can help attract and retain subscribers who are interested in mature and potentially controversial themes. Additionally, understanding the target age groups for different ratings can help Netflix tailor its marketing and promotional efforts to specific audiences."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# group movies by 'rating' and count the number of movies in each rating category\n",
        "m_ratings = movies.groupby(['rating'])['show_id'].count().reset_index(name='count').sort_values(by='count',ascending=False)\n",
        "\n",
        "# set figure dimensions\n",
        "fig_dims = (14,7)\n",
        "\n",
        "# create a figure and axis object with specified dimensions\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "\n",
        "# create a point plot using Seaborn's pointplot() function, with 'rating' on the x-axis and 'count' on the y-axis\n",
        "sns.pointplot(x='rating',y='count',data=m_ratings)\n",
        "\n",
        "# set the plot title and font size\n",
        "plt.title('Movie Show Ratings',size='20')\n",
        "\n",
        "# display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The seaorn pointplot effectively shows the distribution of TV show & moviesratings in a clear and concise manner. Overall, this chart provides a quick and informative overview of the ratings landscape for TV shows & movies on Netflix."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the dataset, TV-MA is the most common rating for TV shows, with the highest number of occurrences in the 'rating' column. This indicates that a significant portion of the TV shows available on Netflix are intended for adult audiences.According to the dataset, TV-MA is the most common rating for both movies and TV shows. This indicates that a significant portion of the content available on Netflix is intended for adult audiences. Specifically, TV-MA has the highest number of occurrences in the 'rating' column for TV shows, while for movies it is also the most common rating. This suggests that Netflix's content caters to a primarily adult demographic, with a focus on mature and potentially controversial themes."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can have a positive impact on Netflix's business strategy. Knowing that TV-MA is the most common rating for both movies and TV shows, Netflix can continue to focus on producing and acquiring content that appeals to adult audiences. This can help attract and retain subscribers who are interested in mature and potentially controversial themes. Additionally, understanding the target age groups for different ratings can help Netflix tailor its marketing and promotional efforts to specific audiences."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Create a figure and set its size\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "# Extract the duration values as integers using regex and plot a histogram\n",
        "sns.histplot(movies['duration'].str.extract('(\\d+)').astype(int), kde=False, color='red')\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Distribution of Movie Durations', fontweight='bold')\n",
        "\n",
        "# Set the x-axis label\n",
        "plt.xlabel('Duration (minutes)')\n",
        "\n",
        "# Set the y-axis label\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For movies: Histogram along with the KDE line lets us visualize the density & the distribution of the feature. The mean & medain dashed lines also gives us the level of skewness.\n",
        "For TV shows: Countplot is one of the best way to visualize the value count distribution of a categorical variable."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the movies in Netflix, most of them range in 70-120 mins, with the median being 90 mins. For TV shows, the TV shows range from 1-9 seasons, with the most TV shows being 1 season, later being cancelled."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can potentially help create a positive business impact as it allows movie studios and streaming platforms to better understand their audience and tailor their content accordingly. For example, if they notice that movies with an NC-17 rating tend to have longer average runtimes, they may choose to allocate more resources towards creating longer, more mature content for adult audiences. Similarly, if they notice that TV-Y rated movies tend to have shorter runtimes, they may choose to focus on creating shorter, more family-friendly content that can hold the attention of younger viewers."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(30, 6))\n",
        "\n",
        "# Create a count plot of TV show durations\n",
        "sns.countplot(x=tv_shows['duration'], data=tv_shows, order=tv_shows['duration'].value_counts().index)\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title(\"Distribution of TV Show Durations\", fontweight='bold')\n",
        "\n",
        "# Set the x-axis label\n",
        "plt.xlabel(\"Duration (seasons)\")\n",
        "\n",
        "# Set the y-axis label\n",
        "plt.ylabel(\"Count\")\n",
        "\n",
        "# Rotate the x-axis labels\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For movies: Histogram along with the KDE line lets us visualize the density & the distribution of the feature. The mean & medain dashed lines also gives us the level of skewness.\n",
        "For TV shows: Countplot is one of the best way to visualize the value count distribution of a categorical variable."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the movies in Netflix, most of them range in 70-120 mins, with the median being 90 mins. For TV shows, the TV shows range from 1-9 seasons, with the most TV shows being 1 season, later being cancelled."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can potentially help create a positive business impact as it allows movie studios and streaming platforms to better understand their audience and tailor their content accordingly. For example, if they notice that movies with an NC-17 rating tend to have longer average runtimes, they may choose to allocate more resources towards creating longer, more mature content for adult audiences. Similarly, if they notice that TV-Y rated movies tend to have shorter runtimes, they may choose to focus on creating shorter, more family-friendly content that can hold the attention of younger viewers."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "#Top 10 genres of movies\n",
        "\n",
        "top10_movies = movies['listed_in'].value_counts().index[0:10]\n",
        "\n",
        "#Visualization of code\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.countplot(y='listed_in', data=movies, order=top10_movies, palette='muted')\n",
        "plt.title('Top 10 Genres of Movies', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Count', fontsize=14)\n",
        "plt.ylabel('Genre', fontsize=14)\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Movies & TV shows: Countplot is one of the best way to visualize the value count distribution of a categorical variable."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix offers a diverse range of TV show genres, each with its own unique flavor and appeal. However, one genre that stands out as a perennial favorite among viewers of all ages is kids TV.\n",
        "\n",
        "With an impressive selection of animated and live-action shows, Netflix's kids TV category is the perfect destination for families looking for high-quality, entertaining content that is both fun and educational. From beloved classics like SpongeBob SquarePants and Power Rangers to exciting new series like Carmen Sandiego and The Dragon Prince, Netflix's kids TV library has something for every young viewer.\n",
        "\n",
        "Moreover, Netflix's kids TV category is designed with parents in mind, offering a safe and secure viewing environment that allows them to have peace of mind while their kids enjoy their favorite shows. The parental controls feature allows parents to set age-appropriate content filters, monitor viewing history, and restrict access to certain shows or movies."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top genre for TV shows on Netflix is kids TV, which includes a range of educational and entertaining content for children of all ages. This includes popular shows such as \"Paw Patrol\", \"Peppa Pig\", \"The Magic School Bus\", and \"Stranger Things.\"\n",
        "\n",
        "The insights gained from this information could definitely have a positive business impact. By knowing which genres are most popular, Netflix can tailor their content offerings and marketing strategies to appeal to their target audience. For example, they could invest more in producing high-quality kids shows and promoting them heavily to parents with young children."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "#Top 10 Genres of Tv shows\n",
        "top10_tvshows = tv_shows['listed_in'].value_counts().index[0:10]\n",
        "\n",
        "#Visualization\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.countplot(y='listed_in', data=tv_shows, order=top10_tvshows, palette='pastel')\n",
        "plt.title('Top 10 Genres of TV Shows', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Count', fontsize=14)\n",
        "plt.ylabel('Genre', fontsize=14)\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Movies & TV shows: Countplot is one of the best way to visualize the value count distribution of a categorical variable."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix offers a diverse range of TV show genres, each with its own unique flavor and appeal. However, one genre that stands out as a perennial favorite among viewers of all ages is kids TV.\n",
        "\n",
        "With an impressive selection of animated and live-action shows, Netflix's kids TV category is the perfect destination for families looking for high-quality, entertaining content that is both fun and educational. From beloved classics like SpongeBob SquarePants and Power Rangers to exciting new series like Carmen Sandiego and The Dragon Prince, Netflix's kids TV library has something for every young viewer.\n",
        "\n",
        "Moreover, Netflix's kids TV category is designed with parents in mind, offering a safe and secure viewing environment that allows them to have peace of mind while their kids enjoy their favorite shows. The parental controls feature allows parents to set age-appropriate content filters, monitor viewing history, and restrict access to certain shows or movies."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top genre for TV shows on Netflix is kids TV, which includes a range of educational and entertaining content for children of all ages. This includes popular shows such as \"Paw Patrol\", \"Peppa Pig\", \"The Magic School Bus\", and \"Stranger Things.\"\n",
        "\n",
        "The insights gained from this information could definitely have a positive business impact. By knowing which genres are most popular, Netflix can tailor their content offerings and marketing strategies to appeal to their target audience. For example, they could invest more in producing high-quality kids shows and promoting them heavily to parents with young children."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.pairplot(df, corner=True)"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Countplot is one of the best way to visualize the value count distribution of a categorical variable."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moreover, Netflix's kids TV category is designed with parents in mind, offering a safe and secure viewing environment that allows them to have peace of mind while their kids enjoy their favorite shows. The parental controls feature allows parents to set age-appropriate content filters, monitor viewing history, and restrict access to certain shows or movies."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix offers a diverse range of TV show genres, each with its own unique flavor and appeal. However, one genre that stands out as a perennial favorite among viewers of all ages is kids TV."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix has the highest number of content in the United States, followed by India. India has the highest number of movies on Netflix\n",
        "\n",
        "\n",
        "\n",
        "1.  Null hypothesis H0: The average number of movies on Netflix in the United States is equal to the average number of movies on Netflix in India.\n",
        "\n",
        "2.  Alternate hypothesis Ha: The average number of movies on Netflix in the United States is greater than the average number of movies on Netflix in India.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Filter by country\n",
        "us_movies = movies[movies.country == 'United States']\n",
        "india_movies = movies[movies.country == 'India']\n",
        "\n",
        "# Perform t-test\n",
        "t, p = ttest_ind(us_movies['release_year'], india_movies['release_year'], equal_var=False)\n",
        "\n",
        "# Print the results\n",
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "    print(\"Reject null hypothesis. The average number of movies on Netflix in the United States is greater than the average number of movies on Netflix in India.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a two-sample t-test (also known as an independent samples t-test or unpaired t-test) to obtain the p-value. Specifically, I used the ttest_ind function from the scipy.stats module to perform the t-test. This test is appropriate for comparing the means of two independent samples, which is what we're doing here by comparing the number of movies on Netflix in the United States and India."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the two-sample t-test because it's appropriate for comparing the means of two independent samples, which is exactly what we're doing here. We have two independent samples of movies on Netflix in the United States and India, and we want to test whether the mean number of movies in the United States is significantly different from the mean number of movies in India.\n",
        "\n",
        "The t-test is also appropriate because the population standard deviations are unknown, and we're working with relatively small sample sizes (compared to the total number of movies on Netflix), so we need to use the sample standard deviations to estimate the population standard deviations."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the countplot, it appears that Netflix adds the highest number of movies and TV shows during the period between October and January. This period seems to be the busiest time of year for Netflix in terms of adding new content to its platform.\n",
        "\n",
        "*   Null hypothesis H0: There is no significant difference in the number of movies and TV shows added by Netflix across different months.\n",
        "*  Alternate hypothesis Ha: There is a significant difference in the number of movies and TV shows added by Netflix across different months.\n",
        "\n"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Convert the \"date_added\" column to datetime format\n",
        "df[\"date_added\"] = pd.to_datetime(df[\"date_added\"])\n",
        "\n",
        "# Extract the month from the \"date_added\" column\n",
        "df[\"month_added\"] = df[\"date_added\"].dt.month_name()\n",
        "\n",
        "# Create a contingency table of the number of new movies and TV shows added by month\n",
        "contingency_table = pd.crosstab(df[\"type\"], df[\"month_added\"])\n",
        "\n",
        "# Perform a chi-square test for independence\n",
        "chi2_statistic, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"Chi-square statistic:\", chi2_statistic)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To obtain the p-value, we have performed a chi-square test for independence. The chi-square test is used to determine if there is a significant association between two categorical variables. In this case, we wanted to test if there was a significant association between the time of year and the number of new movies and TV shows added to Netflix. The test involves comparing the observed frequencies of the contingency table (which shows the distribution of the data) to the expected frequencies under the assumption of independence."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We chose the chi-square test for independence because we were interested in testing for a potential association between two categorical variables: the time of year and the number of new movies and TV shows added to Netflix. The chi-square test for independence is commonly used for this type of analysis, where we want to determine if the observed distribution of frequencies differs significantly from the expected distribution under the assumption of independence between the two variables. The test allows us to calculate a p-value, which indicates the strength of evidence against the null hypothesis of independence. If the p-value is less than the significance level (usually 0.05), we reject the null hypothesis and conclude that there is a significant association between the two variables. Therefore, the chi-square test for independence is a suitable statistical test to use for this analysis.."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of movies on Netflix is greater than the number of TV shows, with 5372 movies and 2398 TV shows currently available on the platform.\n",
        "\n",
        "*   Null hypothesis H0: The number of movies and TV shows on Netflix is not significantly different.\n",
        "*   Alternate hypothesis Ha: The number of movies on Netflix is significantly greater than the number of TV shows.\n",
        "\n"
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "# Count the number of movies and TV shows\n",
        "n_movies = df[df['type'] == 'Movie'].count()['type']\n",
        "n_tv_shows = df[df['type'] == 'TV Show'].count()['type']\n",
        "\n",
        "# Set the counts and sample sizes for the z-test\n",
        "counts = [n_movies, n_tv_shows]\n",
        "nobs = [len(df), len(df)]\n",
        "\n",
        "# Perform the z-test assuming equal proportions\n",
        "z_stat, p_val = proportions_ztest(counts, nobs, value=0, alternative='larger')\n",
        "\n",
        "# Print the results\n",
        "print('Number of movies:', n_movies)\n",
        "print('Number of TV shows:', n_tv_shows)\n",
        "print('z-statistic:', z_stat)\n",
        "print('p-value:', p_val)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a two-sample z-test for proportions to obtain the p-value. The null hypothesis for the test is that the proportion of movies and TV shows on Netflix is equal, while the alternative hypothesis is that the proportion of movies is greater than the proportion of TV shows."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the two-sample z-test for proportions to compare the number of movies and TV shows on Netflix because the data consists of two categorical variables (movie or TV show), and we want to test if there is a significant difference between the proportions of these categories in the population. The two-sample z-test for proportions is an appropriate test to use when we have two independent samples, and we want to compare the proportion of successes in each sample. In this case, a success refers to a movie or TV show. The test assumes that the samples are large enough to apply the normal approximation to the binomial distribution. Since we have a large sample size in this case, we can use the z-test for proportions to test the hypothesis of interest."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*  We have already handled the missing values.\n",
        "*  There's no handling outliers, categorical encoding, feature manipulation, data transformation & data scaling.\n",
        "\n"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing \n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating tags column using all text column which one is used for model building purpose.\n",
        "df['tags'] = df['description'] + df['listed_in'] + df['rating'] + df['cast'] + df['country'] "
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tags'][0]"
      ],
      "metadata": {
        "id": "hGAGpRASqzR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "# Lower Casing & Removing Stopwords & Removing White spaces\n",
        "\n",
        "# download the stop words list if it is not already downloaded\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# create a set of English stop words\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# displaying stopwords\n",
        "np.array(stop_words)"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stopwords(text):\n",
        "    '''a function for removing the stopword and lowercase the each word'''\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "9S-FcZwcq-qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying stopwords function.\n",
        "df['tags'] = df['tags'].apply(stopwords)"
      ],
      "metadata": {
        "id": "lxqPt0hVq-3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tags[0]"
      ],
      "metadata": {
        "id": "vggE8w2OrCBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "# function to remove punctuations\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    import string\n",
        "    # replacing the punctuations with no space, which in effect deletes the punctuation marks.\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying remove_punctuation function\n",
        "df['tags'] = df['tags'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "eenrQGZRrMjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tags[0]"
      ],
      "metadata": {
        "id": "V8_pBxrbrOtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "import re\n",
        "\n",
        "text = \"I found a great website at https://www.example.com. Check it out!\"\n",
        "no_url_text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
        "print(no_url_text)"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "text = \"This is an example sentence with some stopwords.\"\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "# Remove stopwords\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "# Join the filtered tokens back into a sentence\n",
        "filtered_text = ' '.join(filtered_tokens)\n",
        "\n",
        "print(filtered_text)"
      ],
      "metadata": {
        "id": "RdlyGvCQsD5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces\n",
        "text = \"    This is an example    sentence with   extra spaces.   \"\n",
        "\n",
        "# Remove leading and trailing white spaces\n",
        "text = text.strip()\n",
        "\n",
        "# Remove extra spaces within the text\n",
        "text = ' '.join(text.split())\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "hILYRwJpsQcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text\n",
        "# Rephrase Text\n",
        "text = \"I found a great website at https://www.example.com. Check it out!\"\n",
        "no_url_text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
        "print(no_url_text)\n"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs from the text\n",
        "import re\n",
        "\n",
        "text = \"I discovered an excellent website at https://www.example.com. Take a look!\"\n",
        "removed_urls = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
        "print(removed_urls)"
      ],
      "metadata": {
        "id": "SrKPgUQrsU5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "# create the object of tfid vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english', lowercase=False, max_features = 10000)   # max features = 10000 to prevent system from crashing\n",
        "\n",
        "# fit the vectorizer using the text data\n",
        "tfidf.fit(df['tags'])\n",
        "\n",
        "# collect the vocabulary items used in the vectorizer\n",
        "dictionary = tfidf.vocabulary_.items()"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dictionary)) #number of independet features created from \"tags\" columns ---> max_features=10000"
      ],
      "metadata": {
        "id": "24yNADflsnJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert vector into array form for clustering\n",
        "vector = tfidf.transform(df['tags']).toarray()\n",
        "\n",
        "# summarize encoded vector\n",
        "print(vector)\n",
        "print(f'shape of the vector : {vector.shape}')\n",
        "print(f'datatype : {type(vector)}')"
      ],
      "metadata": {
        "id": "TN2t7zaWso9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "word = \"running\"\n",
        "stemmed_word = stemmer.stem(word)\n",
        "\n",
        "print(stemmed_word)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "word = \"running\"\n",
        "lemmatized_word = lemmatizer.lemmatize(word)\n",
        "\n",
        "print(lemmatized_word)"
      ],
      "metadata": {
        "id": "Nplrg3KLs2PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The choice of text normalization techniques depends on the specific requirements of the NLP task and the characteristics of the dataset being processed. Different techniques may be more suitable for different scenarios."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "text = \"I love reading books.\"\n",
        "\n",
        "# Tokenize the text into words\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "# Perform POS tagging\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "# create the object of tfid vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english', lowercase=False, max_features = 10000)   # max features = 10000 to prevent system from crashing\n",
        "\n",
        "# fit the vectorizer using the text data\n",
        "tfidf.fit(df['tags'])\n",
        "\n",
        "# collect the vocabulary items used in the vectorizer\n",
        "dictionary = tfidf.vocabulary_.items()"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dictionary)) #number of independet features created from \"tags\" columns ---> max_features=10000"
      ],
      "metadata": {
        "id": "N3zKqmfQtMoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert vector into array form for clustering\n",
        "vector = tfidf.transform(df['tags']).toarray()\n",
        "\n",
        "# summarize encoded vector\n",
        "print(vector)\n",
        "print(f'shape of the vector : {vector.shape}')\n",
        "print(f'datatype : {type(vector)}')"
      ],
      "metadata": {
        "id": "b_JewFAJtMz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word/Text vectorization is the process of representing words as numerical vectors. This is important in NLP tasks because most machine learning models expect numerical input and cannot work with raw text data directly. Word vectorization allows you to input the words into a machine learning model in a way that preserve the meaning and context of the words. Word vectorization can also be used to measure the similarity between words using vector arithmetic."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, as there 12 columns in our dataset, we need to reduce the dimntionality to reduce complexity."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "# using PCA to reduce dimensionality\n",
        "pca = PCA(random_state=42)\n",
        "pca.fit(vector)"
      ],
      "metadata": {
        "id": "EBUwyb0ft4EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explained variance for different number of components\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.title('PCA - cumulative explained variance vs number of components')\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance')\n",
        "plt.axhline(y= 0.8, color='red', linestyle='--')\n",
        "plt.axvline(x= 3000, color='green', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0boUjTJ0t5Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reducing the dimensions to 3000 using pca\n",
        "pca = PCA(n_components=3000, random_state=42)\n",
        "pca.fit(vector)"
      ],
      "metadata": {
        "id": "5X0SW2OZt-ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformed features\n",
        "X = pca.transform(vector)\n",
        "\n",
        "# shape of transformed vectors\n",
        "X.shape\n"
      ],
      "metadata": {
        "id": "mIzRkW79uAYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use PCA (Principal component Analysis) to reduce the dimensionality of data.\n",
        "\n",
        "Dimensionality reduction is the process of reducing the number of features or dimensions in a dataset while preserving as much information as possible. It is a common step in machine learning and data analysis, as high-dimensional datasets can be difficult to work with and can sometimes suffer from the curse of dimensionality."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. Clusters Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clusters Model - 1 K-Means Clustering"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clusters Model - 1 K-Means Clustering"
      ],
      "metadata": {
        "id": "k-GjIlsk0xxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The k-means algorithm works by first selecting k initial \"centroids,\" or cluster centers, at random from the data. Then, it assigns each sample in the dataset to the nearest centroid, based on some distance metric like Euclidean distance. The algorithm then updates the centroids to be the mean of the samples in each cluster. teratively repeats the process of reassigning samples to the nearest centroids and updating the centroids until convergence. Visualizing the elbow curve and Silhouette score to decide on the optimal number of clusters for K-means clustering algorithm"
      ],
      "metadata": {
        "id": "eYSB0GPT0tSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Elbow method to find the optimal value of k'''\n",
        "\n",
        "# Initialize a list to store the sum of squared errors for each value of k\n",
        "SSE = []\n",
        "\n",
        "for k in range(1, 16):\n",
        "  # Initialize the k-means model with the current value of k\n",
        "  kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "  # Fit the model to the data\n",
        "  kmeans.fit(X)\n",
        "  # Compute the sum of squared errors for the model\n",
        "  SSE.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the values of SSE\n",
        "plt.plot(range(1, 16), SSE)\n",
        "plt.title('The Elbow Method - KMeans clustering')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Sum of squared errors')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''Silhouette score method to find the optimal value of k'''\n",
        "\n",
        "# Initialize a list to store the silhouette score for each value of k\n",
        "silhouette_avg = []\n",
        "\n",
        "for k in range(2, 16):\n",
        "  # Initialize the k-means model with the current value of k\n",
        "  kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "  # Fit the model to the data\n",
        "  kmeans.fit(X)\n",
        "  # Predict the cluster labels for each point in the data\n",
        "  labels = kmeans.labels_\n",
        "  # Compute the silhouette score for the model\n",
        "  score = silhouette_score(X, labels)\n",
        "  silhouette_avg.append(score)\n",
        "  \n",
        "# Plot the Silhouette analysis\n",
        "plt.plot(range(2,16), silhouette_avg)\n",
        "plt.xlabel('Number of clusters') \n",
        "plt.ylabel('Silhouette score')\n",
        "plt.title('Silhouette analysis For Optimal k - KMeans clustering')"
      ],
      "metadata": {
        "id": "w2oaIDs_5jJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   The highest Silhouette score is obtained for 5 clusters.\n",
        "\n",
        "*   Building 5 clusters using the k-means clustering algorithm:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rk9CNeaf78yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering the data into 5 clusters\n",
        "kmeans = KMeans(n_clusters=5, init='k-means++', random_state=33)\n",
        "kmeans.fit(X)"
      ],
      "metadata": {
        "id": "D91Tos9S8Kmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics - distortion, Silhouette score\n",
        "kmeans_distortion = kmeans.inertia_\n",
        "kmeans_silhouette_score = silhouette_score(X, kmeans.labels_)\n",
        "\n",
        "print((kmeans_distortion, kmeans_silhouette_score))"
      ],
      "metadata": {
        "id": "SwMd2f3w8U8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a kmeans cluster number attribute\n",
        "df['kmeans_cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "rENPAzgq8dlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)[['type', 'title', 'cast', 'country', 'rating', 'listed_in', 'description', 'kmeans_cluster']]"
      ],
      "metadata": {
        "id": "0k5z0DvT8gST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(8,5))\n",
        "graph = sns.countplot(x='kmeans_cluster',data=df, hue='type')\n",
        "plt.title('Number of movies and TV shows in each cluster - Kmeans Clustering')\n",
        "\n",
        "# adding value count on the top of bar\n",
        "for p in graph.patches:\n",
        "   graph.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))"
      ],
      "metadata": {
        "id": "wI8Rls5m8lHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successfully built 5 clusters using the k-means clustering algorithm."
      ],
      "metadata": {
        "id": "ypnBTLR58psv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Building wordclouds for different clusters in K-Means Clustering**"
      ],
      "metadata": {
        "id": "4QZbLsRH8uCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kmeans_worldcloud(cluster_number, column_name):\n",
        "  \n",
        "  '''function for Building a wordcloud for the movie/shows'''\n",
        "\n",
        "  df_wordcloud = df[['kmeans_cluster',column_name]].dropna()\n",
        "  df_wordcloud = df_wordcloud[df_wordcloud['kmeans_cluster']==cluster_number]\n",
        "  \n",
        "  # text documents\n",
        "  text = \" \".join(word for word in df_wordcloud[column_name])\n",
        "\n",
        "  # create the word cloud\n",
        "  wordcloud = WordCloud(stopwords=set(STOPWORDS), background_color=\"white\").generate(text)\n",
        "  \n",
        "  # Generate a word cloud image\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "bFjp0n6k8xP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Cloud on \"description\" column for different cluster**"
      ],
      "metadata": {
        "id": "7pURjwdo807j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'description')"
      ],
      "metadata": {
        "id": "_5W0goCO84Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'cast')"
      ],
      "metadata": {
        "id": "QB8tJD2h8_nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'listed_in')"
      ],
      "metadata": {
        "id": "s7CYEs339DST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'country')"
      ],
      "metadata": {
        "id": "C2zd9HPL9HCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'title')"
      ],
      "metadata": {
        "id": "I1nFfNHr9L2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clusters Model - 2 Hierarchical clustering"
      ],
      "metadata": {
        "id": "xqKra66V9QDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying the agglomerative hierarchical clustering algorithm, the resulting clusters are displayed in a dendrogram, which is a tree-like structure. The dendrogram shows the relationships between the clusters at each level of the hierarchy.\n",
        "\n",
        "To determine the optimal number of clusters for our data, we can visually inspect the dendrogram and look for the largest vertical distance that does not intersect any horizontal line. This distance represents the largest distance between any two merged clusters, and thus the point at which the clusters are most dissimilar.\n",
        "\n",
        "We can then draw a horizontal line at this distance and count the number of vertical lines it intersects. This number corresponds to the optimal number of clusters for our data."
      ],
      "metadata": {
        "id": "I_L7WXE69TcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a dendogram to decide the number of clusters\n",
        "plt.figure(figsize=(10, 7))  \n",
        "dend = shc.dendrogram(shc.linkage(X, method='ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Netflix Shows')\n",
        "plt.ylabel('Distance')\n",
        "plt.axhline(y= 4, color='r', linestyle='--')"
      ],
      "metadata": {
        "id": "BlMR_Xks9Wcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**At a distance of 4 units, 7 clusters can be built using the agglomerative clustering algorithm.**\n",
        "\n",
        "Building 7 clusters using the Agglomerative clustering algorithm:"
      ],
      "metadata": {
        "id": "aCFoVWGW9xiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting hierarchical clustering model\n",
        "hierarchical = AgglomerativeClustering(n_clusters=7, affinity='euclidean', linkage='ward')  \n",
        "hierarchical.fit_predict(X)"
      ],
      "metadata": {
        "id": "9nHlfjn1-TvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a hierarchical cluster number attribute\n",
        "df['hierarchical_cluster'] = hierarchical.labels_"
      ],
      "metadata": {
        "id": "d47tYAss-onY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)[['type', 'title', 'cast', 'country', 'rating', 'listed_in', 'description', 'hierarchical_cluster']]"
      ],
      "metadata": {
        "id": "3xjwlMBc-rmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(10,5))\n",
        "graph = sns.countplot(x='hierarchical_cluster',data=df, hue='type')\n",
        "plt.title('Number of movies and tv shows in each cluster - Hierarchical Clustering')\n",
        "\n",
        "# adding value count on the top of bar\n",
        "for p in graph.patches:\n",
        "   graph.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))"
      ],
      "metadata": {
        "id": "0ePFlH7t-u_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successfully built 7 clusters using the Agglomerative (hierarchical) clustering algorithm."
      ],
      "metadata": {
        "id": "dRXnKyJP-yxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hierarchical_worldcloud(cluster_number, column_name):\n",
        "  \n",
        "  '''function for Building a wordcloud for the movie/shows'''\n",
        "\n",
        "  df_wordcloud = df[['hierarchical_cluster',column_name]].dropna()\n",
        "  df_wordcloud = df_wordcloud[df_wordcloud['hierarchical_cluster']==cluster_number]\n",
        "  \n",
        "  # text documents\n",
        "  text = \" \".join(word for word in df_wordcloud[column_name])\n",
        "\n",
        "  # create the word cloud\n",
        "  wordcloud = WordCloud(stopwords=set(STOPWORDS), background_color=\"white\").generate(text)\n",
        "  \n",
        "  # Generate a word cloud image\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "e7aJEzxZ-z0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'title')"
      ],
      "metadata": {
        "id": "vvSlx2xu-5tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'description')"
      ],
      "metadata": {
        "id": "AtXSzg7m--Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'cast')"
      ],
      "metadata": {
        "id": "_J9PNXVo_L6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'country')"
      ],
      "metadata": {
        "id": "NbTbrhjz_QyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'listed_in')"
      ],
      "metadata": {
        "id": "OGisH-TP_VB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommender System"
      ],
      "metadata": {
        "id": "Kkt6-FQs_Z8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining new dataframe for building recommandation system\n",
        "recommender_df = df.copy()\n",
        "\n",
        "# reseting index\n",
        "recommender_df.reset_index(inplace=True)\n",
        "\n",
        "# checking whether or not reset index properly \n",
        "recommender_df[['show_id', 'title', 'tags']]"
      ],
      "metadata": {
        "id": "WmO3Z7AC_ZMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see above dataframe We successfully reset the index. Now dataset is ready to build content based recommandation system"
      ],
      "metadata": {
        "id": "IYVsgBuR_iar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping show-id and index column\n",
        "recommender_df.drop(columns=['index', 'show_id'], inplace=True)\n",
        "     \n",
        "\n",
        "print(f\"before reset index id for movie 'Zero' : {df[df['title'] == 'Zero'].index[0]}\")  # index[0] --> to locate index position\n",
        "print(f\"after reset index id for movie 'Zero': {recommender_df[recommender_df['title'] == 'Zero'].index[0]}\")"
      ],
      "metadata": {
        "id": "d-RfOU5d_iJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calling out transformed array independent features created from tags(cluster) column after performing PCA for dimenssionality reduction.\n",
        "X"
      ],
      "metadata": {
        "id": "NYoJWypS_oyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate cosine similarity\n",
        "similarity = cosine_similarity(X)\n",
        "similarity"
      ],
      "metadata": {
        "id": "b9tYeJVY_sZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function for list down top 10 recommended movie on the basis of cosine similarity score**"
      ],
      "metadata": {
        "id": "RgT1zWC8_yTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(movie):\n",
        "    '''\n",
        "    This function list down top ten movies on the basis of similarity score for that perticular movie.\n",
        "    '''\n",
        "    print(f\"If you liked '{movie}', you may also enjoy: \\n\")\n",
        "\n",
        "    # find out index position\n",
        "    index = recommender_df[recommender_df['title'] == movie].index[0]\n",
        "\n",
        "    # sorting on the basis of simliarity score, In order to find out distaces from recommended one\n",
        "    distances = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda x:x[1])\n",
        "    \n",
        "    # listing top ten recommenaded movie\n",
        "    for i in distances[1:11]:\n",
        "        print(df.iloc[i[0]].title)"
      ],
      "metadata": {
        "id": "rdjaqC1i_zJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('Naruto')"
      ],
      "metadata": {
        "id": "OtzPV9mD_5VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('Phir Hera Pheri')"
      ],
      "metadata": {
        "id": "N5dQvgFp_-Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "A1A4u9KdAFgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our goal was to cluster the shows into groups based on their similarities and differences, ultimately creating a content-based recommender system that suggests 10 shows based on the user's viewing history.\n",
        "\n",
        "With over 7787 records and 11 attributes, we began our adventure by delving into the dataset's missing values and performing exploratory data analysis (EDA). Our findings revealed that Netflix boasts more movies than TV shows, with a rapidly growing collection of shows from the United States.\n",
        "\n",
        "To cluster the shows, we focused on six key attributes: director, cast, country, genre, rating, and description. We transformed these attributes into a 10000-feature TFIDF vectorization, then used Principal Component Analysis (PCA) to tackle the curse of dimensionality. By reducing the components to 3000, we were able to capture more than 80% of the variance.\n",
        "\n",
        "Next, we used two clustering algorithms, K-Means and Agglomerative clustering, to group the shows. K-Means determined that the optimal number of clusters was 5, as confirmed by the elbow method and Silhouette score analysis. Meanwhile, Agglomerative clustering suggested 7 clusters, which we visualized using a dendrogram.\n",
        "\n",
        "But we didn't stop there. We then created a content-based recommender system using the similarity matrix obtained through cosine similarity. This system provides personalized recommendations based on the type of show the user has watched, giving them 10 top-notch suggestions to explore."
      ],
      "metadata": {
        "id": "2YvLtLATAIiw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "dATs7MhjAL6G"
      }
    }
  ]
}